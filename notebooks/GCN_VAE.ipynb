{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "import model\n",
    "from preprocessing import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/eos/home-n/nchernya/MLHEP/mpp_tutorials/ADC2021-examplecode/preprocessing.py:20: RuntimeWarning: divide by zero encountered in power\n",
      "  D = np.nan_to_num(np.power(D,-0.5), posinf=0, neginf=0) # normalize (**-(1/2))\n"
     ]
    }
   ],
   "source": [
    "#BG\n",
    "filename_bg = 'background_for_training.h5'\n",
    "batch_size = 128\n",
    "nodes_n, feat_sz, particles_bg, A_bg, A_tilde_bg = prepare_data(filename_bg,0,batch_size*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2560, 19, 4) (2560, 19, 19) (2560, 19, 19)\n"
     ]
    }
   ],
   "source": [
    "print(particles_bg.shape, A_tilde_bg.shape, A_bg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_features (InputLa [(None, 19, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input_adjacency (InputL [(None, 19, 19)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution (GraphConvolu (None, 19, 6)        54          encoder_input_features[0][0]     \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_1 (GraphConvo (None, 19, 8)        104         graph_convolution[0][0]          \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_2 (GraphConvo (None, 19, 4)        68          graph_convolution_1[0][0]        \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_3 (GraphConvo (None, 19, 3)        27          graph_convolution_2[0][0]        \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_4 (GraphConvo (None, 19, 2)        14          graph_convolution_3[0][0]        \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_5 (GraphConvo (None, 19, 1)        5           graph_convolution_4[0][0]        \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 272\n",
      "Trainable params: 272\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gnn = GraphAutoencoder(nodes_n=nodes_n, feat_sz=feat_sz, activation=tf.nn.tanh)\n",
    "gnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 38ms/step - val_loss: 0.6808\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 1s 40ms/step - val_loss: 0.6862\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.6743\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 33ms/step - val_loss: 0.6746\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 1s 37ms/step - val_loss: 0.6738\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 31ms/step - val_loss: 0.6736\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 30ms/step - val_loss: 0.6735\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 31ms/step - val_loss: 0.6732\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.6729\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.6724\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 31ms/step - val_loss: 0.6716\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 30ms/step - val_loss: 0.6700\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.6661\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.6557\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.6407\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.6293\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.6211\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.6148\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.6097\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.6054\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.6018\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5986\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5958\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.5933\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.5910\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 33ms/step - val_loss: 0.5890\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5871\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5854\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 33ms/step - val_loss: 0.5838\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.5823\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5809\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 1s 37ms/step - val_loss: 0.5796\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5784\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.5773\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.5762\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5753\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 1s 37ms/step - val_loss: 0.5743\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5734\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.5725\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.5717\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5709\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.5702\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5695\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 28ms/step - val_loss: 0.5688\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 31ms/step - val_loss: 0.5681\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 30ms/step - val_loss: 0.5675\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5669\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 1s 40ms/step - val_loss: 0.5663\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.5657\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 1s 37ms/step - val_loss: 0.5652\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 1s 37ms/step - val_loss: 0.5646\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.5641\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.5637\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 33ms/step - val_loss: 0.5632\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 1s 44ms/step - val_loss: 0.5627\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.5623\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.5618\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5614\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5610\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5606\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5602\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5599\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 1s 39ms/step - val_loss: 0.5595\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5591\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 30ms/step - val_loss: 0.5588\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 31ms/step - val_loss: 0.5584\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 29ms/step - val_loss: 0.5581\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5578\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 30ms/step - val_loss: 0.5575\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5572\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5569\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.5566\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.5563\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 1s 39ms/step - val_loss: 0.5560\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 33ms/step - val_loss: 0.5558\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5555\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5552\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 31ms/step - val_loss: 0.5550\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 31ms/step - val_loss: 0.5547\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5545\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.5542\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5540\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 33ms/step - val_loss: 0.5538\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 1s 37ms/step - val_loss: 0.5535\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 31ms/step - val_loss: 0.5533\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 1s 34ms/step - val_loss: 0.5531\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 31ms/step - val_loss: 0.5529\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 30ms/step - val_loss: 0.5527\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 33ms/step - val_loss: 0.5525\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.5523\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5521\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 33ms/step - val_loss: 0.5519\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 1s 37ms/step - val_loss: 0.5517\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 30ms/step - val_loss: 0.5515\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 32ms/step - val_loss: 0.5513\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 1s 35ms/step - val_loss: 0.5511\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 1s 39ms/step - val_loss: 0.5510\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 1s 42ms/step - val_loss: 0.5507\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 1s 36ms/step - val_loss: 0.5506\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 1s 37ms/step - val_loss: 0.5504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4c5534ce50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, verbose=1)]\n",
    "gnn.fit((particles_bg, A_tilde_bg), A_bg, epochs=100, batch_size=128, validation_split=0.25, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict BG and Sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sig, A_pred_sig = gnn((particles_sig, A_tilde_sig))\n",
    "z_bg, A_pred_bg = gnn((particles_bg, A_tilde_bg))\n",
    "loss_signal = tf.math.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(A_sig, A_pred_sig), axis=(1,2)).numpy()\n",
    "loss_bg = tf.math.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(A_bg, A_pred_bg), axis=(1,2)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_score = np.max(np.max(loss_bg))#,np.max(loss_bg_dist))\n",
    "# plot BG\n",
    "plt.figure()\n",
    "plt.hist(loss_bg, bins=100, label='BG', density=True, range=(0, max_score), \n",
    "         histtype='step', fill=False, linewidth=1.5,color='g')\n",
    "plt.hist(loss_signal, bins=100, label='SIG', density=True, range=(0, max_score), \n",
    "         histtype='step', fill=False, linewidth=1.5,color='r')\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"AE Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying GCN VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threeD_loss_manual(inputs, outputs):\n",
    "    distances = np.sum(np.subtract(inputs[:,:,np.newaxis,:],outputs[:,np.newaxis,:,:])**2, axis=-1)\n",
    "    min_dist_to_inputs = np.min(distances,axis=1)\n",
    "    min_dist_to_outputs = np.min(distances,axis=2)\n",
    "    return np.sum(min_dist_to_inputs,axis=1) + np.sum(min_dist_to_outputs,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_features (InputLa [(None, 19, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input_adjacency (InputL [(None, 19, 19)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution (GraphConvolu (None, 19, 3)        27          encoder_input_features[0][0]     \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_1 (GraphConvo (None, 19, 2)        14          graph_convolution[0][0]          \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 38)           0           graph_convolution_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 19)           741         flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           200         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_shape_2 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           200         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_RandomStandardNorma [(None, None)]       0           tf_op_layer_shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, 10)]         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, None)]       0           tf_op_layer_RandomStandardNormal[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp (TensorFlowOpLa [(None, 10)]         0           tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add (TensorFlowOpLa [(None, None)]       0           tf_op_layer_Mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_2 (TensorFlowOp [(None, 10)]         0           tf_op_layer_Exp[0][0]            \n",
      "                                                                 tf_op_layer_Add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 10)]         0           dense_1[0][0]                    \n",
      "                                                                 tf_op_layer_Mul_2[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 1,182\n",
      "Trainable params: 1,182\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_features (InputLa [(None, 19, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input_adjacency (InputL [(None, 19, 19)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_2 (GraphConvo (None, 19, 3)        27          encoder_input_features[0][0]     \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_3 (GraphConvo (None, 19, 2)        14          graph_convolution_2[0][0]        \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 38)           0           graph_convolution_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 19)           741         flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           200         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_4 (TensorFlow [(2,)]               0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_shape_5 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           200         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_RandomStandardNorma [(None, None)]       0           tf_op_layer_shape_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_4 (TensorFlowOp [(None, 10)]         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_3 (TensorFlowOp [(None, None)]       0           tf_op_layer_RandomStandardNormal_\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp_1 (TensorFlowOp [(None, 10)]         0           tf_op_layer_Mul_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_1 (TensorFlowOp [(None, None)]       0           tf_op_layer_Mul_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_5 (TensorFlowOp [(None, 10)]         0           tf_op_layer_Exp_1[0][0]          \n",
      "                                                                 tf_op_layer_Add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 10)]         0           dense_4[0][0]                    \n",
      "                                                                 tf_op_layer_Mul_5[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 1,182\n",
      "Trainable params: 1,182\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input_latent_space (Inp [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 19)           209         decoder_input_latent_space[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 38)           760         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 19, 2)        0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_adjacency (InputL [(None, 19, 19)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_4 (GraphConvo (None, 19, 3)        15          reshape[0][0]                    \n",
      "                                                                 decoder_input_adjacency[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_5 (GraphConvo (None, 19, 4)        28          graph_convolution_4[0][0]        \n",
      "                                                                 decoder_input_adjacency[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 1,012\n",
      "Trainable params: 1,012\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import model\n",
    "reload(model)\n",
    "from model import *\n",
    "gcnvae = GCNVariationalAutoEncoder(nodes_n=nodes_n, feat_sz=feat_sz, activation=tf.nn.tanh)\n",
    "gcnvae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.0839 - loss_reco: 3.0712 - loss_latent: 0.0127WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 3.0622 - loss_reco: 3.0499 - loss_latent: 0.0123\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.5114 - loss_reco: 2.5098 - loss_latent: 0.0016WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 2.4927 - loss_reco: 2.4911 - loss_latent: 0.0016\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.3853 - loss_reco: 2.3843 - loss_latent: 9.5940e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 2.3778 - loss_reco: 2.3769 - loss_latent: 9.2517e-04\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.3287 - loss_reco: 2.3278 - loss_latent: 9.4902e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 2.3338 - loss_reco: 2.3329 - loss_latent: 9.3111e-04\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2987 - loss_reco: 2.2975 - loss_latent: 0.0012WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 2.2990 - loss_reco: 2.2979 - loss_latent: 0.0011\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2707 - loss_reco: 2.2702 - loss_latent: 4.6307e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 2.2634 - loss_reco: 2.2629 - loss_latent: 4.6073e-04\n",
      "Epoch 7/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.2654 - loss_reco: 2.2648 - loss_latent: 5.2856e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 2.2357 - loss_reco: 2.2352 - loss_latent: 5.0313e-04\n",
      "Epoch 8/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.2179 - loss_reco: 2.2175 - loss_latent: 3.9179e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 2.2469 - loss_reco: 2.2466 - loss_latent: 3.6315e-04\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2256 - loss_reco: 2.2253 - loss_latent: 2.2433e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 2.2294 - loss_reco: 2.2292 - loss_latent: 2.1518e-04\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2224 - loss_reco: 2.2221 - loss_latent: 2.3441e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 2.2242 - loss_reco: 2.2240 - loss_latent: 2.5404e-04\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2199 - loss_reco: 2.2198 - loss_latent: 9.9203e-05WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 2.2188 - loss_reco: 2.2187 - loss_latent: 1.0514e-04\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2168 - loss_reco: 2.2166 - loss_latent: 1.8527e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 2.2038 - loss_reco: 2.2036 - loss_latent: 1.8221e-04\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2143 - loss_reco: 2.2141 - loss_latent: 2.5197e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 2.2356 - loss_reco: 2.2353 - loss_latent: 3.7760e-04\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2132 - loss_reco: 2.2130 - loss_latent: 1.5841e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 2.2178 - loss_reco: 2.2176 - loss_latent: 1.5215e-04\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2113 - loss_reco: 2.2109 - loss_latent: 4.0089e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 2.2229 - loss_reco: 2.2224 - loss_latent: 5.7503e-04\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2108 - loss_reco: 2.2097 - loss_latent: 0.0011WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 2.2126 - loss_reco: 2.2115 - loss_latent: 0.0011\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2098 - loss_reco: 2.2095 - loss_latent: 3.6282e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 2.2034 - loss_reco: 2.2030 - loss_latent: 3.5036e-04\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2077 - loss_reco: 2.2075 - loss_latent: 1.6623e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 2.2041 - loss_reco: 2.2039 - loss_latent: 1.5930e-04\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2050 - loss_reco: 2.2049 - loss_latent: 1.7399e-04WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 2.2233 - loss_reco: 2.2232 - loss_latent: 1.6673e-04\n",
      "Epoch 20/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.2017 - loss_reco: 2.2017 - loss_latent: 7.5726e-05WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 2.2039 - loss_reco: 2.2038 - loss_latent: 7.5722e-05\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2005 - loss_reco: 2.2005 - loss_latent: 3.6056e-05WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 2.1848 - loss_reco: 2.1847 - loss_latent: 3.4553e-05\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1983 - loss_reco: 2.1983 - loss_latent: 7.0873e-06WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 2.2061 - loss_reco: 2.2061 - loss_latent: 1.1802e-05\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1966 - loss_reco: 2.1966 - loss_latent: 5.1928e-06WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 2.1904 - loss_reco: 2.1904 - loss_latent: 4.9537e-06\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1956 - loss_reco: 2.1956 - loss_latent: 4.0176e-06WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 2.2116 - loss_reco: 2.2116 - loss_latent: 3.8404e-06\n",
      "Epoch 25/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1967 - loss_reco: 2.1967 - loss_latent: 4.0421e-06WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 2.1933 - loss_reco: 2.1933 - loss_latent: 5.1694e-06\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1941 - loss_reco: 2.1941 - loss_latent: 4.2287e-05WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 2.2074 - loss_reco: 2.2074 - loss_latent: 4.0736e-05\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1933 - loss_reco: 2.1933 - loss_latent: 7.0584e-06WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 2.2012 - loss_reco: 2.2012 - loss_latent: 6.8239e-06\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1929 - loss_reco: 2.1929 - loss_latent: 2.6425e-06WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 2.1819 - loss_reco: 2.1819 - loss_latent: 2.5276e-06\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1926 - loss_reco: 2.1926 - loss_latent: 1.3892e-06WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 2.2016 - loss_reco: 2.2016 - loss_latent: 1.3283e-06\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1922 - loss_reco: 2.1922 - loss_latent: 8.2049e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 2.2204 - loss_reco: 2.2204 - loss_latent: 1.4831e-06\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1918 - loss_reco: 2.1918 - loss_latent: 6.3896e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 2.1960 - loss_reco: 2.1960 - loss_latent: 6.0995e-07\n",
      "Epoch 32/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.2138 - loss_reco: 2.2138 - loss_latent: 3.1874e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 2.1716 - loss_reco: 2.1716 - loss_latent: 2.9207e-07\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1917 - loss_reco: 2.1917 - loss_latent: 2.2352e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 2.1907 - loss_reco: 2.1907 - loss_latent: 2.9745e-07\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1915 - loss_reco: 2.1915 - loss_latent: 3.5142e-05WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 2.1860 - loss_reco: 2.1860 - loss_latent: 3.4997e-05\n",
      "Epoch 35/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1749 - loss_reco: 2.1749 - loss_latent: 9.0398e-06WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 2.2055 - loss_reco: 2.2055 - loss_latent: 8.4114e-06\n",
      "Epoch 36/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1906 - loss_reco: 2.1906 - loss_latent: 1.5735e-06WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 2.1905 - loss_reco: 2.1905 - loss_latent: 1.4892e-06\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1908 - loss_reco: 2.1908 - loss_latent: 3.9823e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 2.2007 - loss_reco: 2.2007 - loss_latent: 3.8437e-07\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1904 - loss_reco: 2.1904 - loss_latent: 2.4133e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 2.1719 - loss_reco: 2.1719 - loss_latent: 2.3154e-07\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1902 - loss_reco: 2.1902 - loss_latent: 6.2317e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 2.2032 - loss_reco: 2.2032 - loss_latent: 5.9435e-07\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1904 - loss_reco: 2.1904 - loss_latent: 2.9447e-06WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 2.1829 - loss_reco: 2.1829 - loss_latent: 3.3177e-06\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1902 - loss_reco: 2.1902 - loss_latent: 3.2135e-06WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 2.2100 - loss_reco: 2.2100 - loss_latent: 3.0976e-06\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1904 - loss_reco: 2.1904 - loss_latent: 6.5883e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 2.1865 - loss_reco: 2.1865 - loss_latent: 6.3157e-07\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 2.1902 - loss_reco: 2.1902 - loss_latent: 3.4333e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 2.1889 - loss_reco: 2.1889 - loss_latent: 3.2897e-07\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1901 - loss_reco: 2.1901 - loss_latent: 2.3684e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 2.1994 - loss_reco: 2.1994 - loss_latent: 2.2712e-07\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1899 - loss_reco: 2.1899 - loss_latent: 4.2857e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 2.1893 - loss_reco: 2.1893 - loss_latent: 6.0118e-07\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1900 - loss_reco: 2.1900 - loss_latent: 1.3758e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 2.1962 - loss_reco: 2.1962 - loss_latent: 2.0075e-07\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1901 - loss_reco: 2.1901 - loss_latent: 6.4487e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 2.1997 - loss_reco: 2.1997 - loss_latent: 6.2835e-08\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1897 - loss_reco: 2.1897 - loss_latent: 6.2998e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 2.1964 - loss_reco: 2.1964 - loss_latent: 6.4823e-08\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1897 - loss_reco: 2.1897 - loss_latent: 2.9504e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 2.1725 - loss_reco: 2.1725 - loss_latent: 2.8383e-08\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1894 - loss_reco: 2.1894 - loss_latent: 4.1723e-09WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 2.1952 - loss_reco: 2.1952 - loss_latent: 4.1156e-09\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1893 - loss_reco: 2.1893 - loss_latent: 1.0729e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 2.1926 - loss_reco: 2.1926 - loss_latent: 1.0644e-08\n",
      "Epoch 52/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1842 - loss_reco: 2.1842 - loss_latent: 4.2351e-09WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 2.1937 - loss_reco: 2.1937 - loss_latent: 4.3994e-09\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1894 - loss_reco: 2.1894 - loss_latent: 7.1526e-09WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 2.1963 - loss_reco: 2.1963 - loss_latent: 7.9473e-09\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1893 - loss_reco: 2.1893 - loss_latent: 2.4632e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 2.1969 - loss_reco: 2.1969 - loss_latent: 2.3828e-07\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1891 - loss_reco: 2.1891 - loss_latent: 1.0744e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 2.1896 - loss_reco: 2.1896 - loss_latent: 1.0331e-07\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1894 - loss_reco: 2.1894 - loss_latent: 2.3097e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 2.1926 - loss_reco: 2.1926 - loss_latent: 2.2990e-08\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1892 - loss_reco: 2.1892 - loss_latent: 1.0729e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 2.1949 - loss_reco: 2.1949 - loss_latent: 1.0644e-08\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1896 - loss_reco: 2.1896 - loss_latent: 1.1057e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 2.1822 - loss_reco: 2.1822 - loss_latent: 1.0871e-07\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1892 - loss_reco: 2.1892 - loss_latent: 1.1086e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 2.1748 - loss_reco: 2.1748 - loss_latent: 1.2389e-07\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1893 - loss_reco: 2.1893 - loss_latent: 1.1906e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 2.1888 - loss_reco: 2.1888 - loss_latent: 1.1509e-07\n",
      "Epoch 61/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1913 - loss_reco: 2.1913 - loss_latent: 1.4274e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 2.1872 - loss_reco: 2.1872 - loss_latent: 1.6604e-08\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1893 - loss_reco: 2.1893 - loss_latent: 5.1111e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 2.1960 - loss_reco: 2.1960 - loss_latent: 5.8469e-08\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1893 - loss_reco: 2.1893 - loss_latent: 3.2917e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 2.1946 - loss_reco: 2.1946 - loss_latent: 3.1747e-07\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1893 - loss_reco: 2.1893 - loss_latent: 1.1146e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 2.2008 - loss_reco: 2.2008 - loss_latent: 1.0700e-07\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1891 - loss_reco: 2.1891 - loss_latent: 1.4305e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 2.1898 - loss_reco: 2.1898 - loss_latent: 1.3766e-08\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1892 - loss_reco: 2.1892 - loss_latent: 1.9670e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 2.1754 - loss_reco: 2.1754 - loss_latent: 1.9017e-08\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1893 - loss_reco: 2.1893 - loss_latent: 1.0133e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 2.1897 - loss_reco: 2.1897 - loss_latent: 9.7922e-09\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1890 - loss_reco: 2.1890 - loss_latent: 9.3877e-09WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 2.1916 - loss_reco: 2.1916 - loss_latent: 9.6503e-09\n",
      "Epoch 69/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1823 - loss_reco: 2.1823 - loss_latent: 4.0782e-09WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 2.1956 - loss_reco: 2.1956 - loss_latent: 4.5413e-09\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1897 - loss_reco: 2.1897 - loss_latent: 1.3858e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 2.2072 - loss_reco: 2.2072 - loss_latent: 1.4617e-08\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1895 - loss_reco: 2.1895 - loss_latent: 3.6359e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 2.1871 - loss_reco: 2.1871 - loss_latent: 3.5763e-08\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1894 - loss_reco: 2.1894 - loss_latent: 9.5367e-09WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 2.1866 - loss_reco: 2.1866 - loss_latent: 9.3664e-09\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1893 - loss_reco: 2.1893 - loss_latent: 1.8328e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 2.1951 - loss_reco: 2.1951 - loss_latent: 2.5119e-08\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1892 - loss_reco: 2.1892 - loss_latent: 6.4746e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 2.1964 - loss_reco: 2.1964 - loss_latent: 6.3124e-07\n",
      "Epoch 75/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1702 - loss_reco: 2.1702 - loss_latent: 1.4587e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 2.2064 - loss_reco: 2.2064 - loss_latent: 1.3823e-07\n",
      "Epoch 76/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1987 - loss_reco: 2.1987 - loss_latent: 2.3999e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 2.1805 - loss_reco: 2.1805 - loss_latent: 2.2848e-08\n",
      "Epoch 77/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1771 - loss_reco: 2.1771 - loss_latent: 9.5681e-09WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 2.1998 - loss_reco: 2.1998 - loss_latent: 1.8591e-08\n",
      "Epoch 78/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.2014 - loss_reco: 2.2014 - loss_latent: 4.5645e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 2.1782 - loss_reco: 2.1782 - loss_latent: 4.4136e-08\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1890 - loss_reco: 2.1890 - loss_latent: 1.0416e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 2.2004 - loss_reco: 2.2004 - loss_latent: 1.0289e-07\n",
      "Epoch 80/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1921 - loss_reco: 2.1921 - loss_latent: 6.4938e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 2.1861 - loss_reco: 2.1861 - loss_latent: 6.2443e-08\n",
      "Epoch 81/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1904 - loss_reco: 2.1904 - loss_latent: 1.7411e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 2.1882 - loss_reco: 2.1882 - loss_latent: 1.8875e-08\n",
      "Epoch 82/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.2078 - loss_reco: 2.2078 - loss_latent: 1.5717e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 2.1727 - loss_reco: 2.1727 - loss_latent: 1.4930e-07\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1891 - loss_reco: 2.1891 - loss_latent: 1.6868e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 2.1939 - loss_reco: 2.1939 - loss_latent: 1.6363e-07\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1893 - loss_reco: 2.1893 - loss_latent: 1.5631e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 2.1992 - loss_reco: 2.1992 - loss_latent: 1.6349e-07\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1931 - loss_reco: 2.1931 - loss_latent: 1.1921e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 2.1851 - loss_reco: 2.1851 - loss_latent: 1.5838e-07\n",
      "Epoch 86/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.2015 - loss_reco: 2.2015 - loss_latent: 2.9802e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 2.1773 - loss_reco: 2.1773 - loss_latent: 2.7844e-07\n",
      "Epoch 87/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1932 - loss_reco: 2.1932 - loss_latent: 3.9559e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 2.1848 - loss_reco: 2.1848 - loss_latent: 4.2660e-07\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1893 - loss_reco: 2.1893 - loss_latent: 2.4926e-05WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 2.1958 - loss_reco: 2.1958 - loss_latent: 2.5059e-05\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1891 - loss_reco: 2.1891 - loss_latent: 1.1973e-05WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 2.1801 - loss_reco: 2.1801 - loss_latent: 1.1571e-05\n",
      "Epoch 90/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1908 - loss_reco: 2.1908 - loss_latent: 2.2134e-06WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 2.1877 - loss_reco: 2.1877 - loss_latent: 2.2492e-06\n",
      "Epoch 91/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1986 - loss_reco: 2.1986 - loss_latent: 8.9799e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 2.1802 - loss_reco: 2.1802 - loss_latent: 8.8030e-07\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1890 - loss_reco: 2.1890 - loss_latent: 2.8983e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 2.1825 - loss_reco: 2.1825 - loss_latent: 2.8454e-07\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1890 - loss_reco: 2.1890 - loss_latent: 2.7731e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 2.1967 - loss_reco: 2.1967 - loss_latent: 2.8553e-07\n",
      "Epoch 94/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1881 - loss_reco: 2.1881 - loss_latent: 1.7819e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 2.1892 - loss_reco: 2.1892 - loss_latent: 1.7484e-07\n",
      "Epoch 95/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.2041 - loss_reco: 2.2041 - loss_latent: 5.9134e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 2.1754 - loss_reco: 2.1754 - loss_latent: 5.9179e-08\n",
      "Epoch 96/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1846 - loss_reco: 2.1846 - loss_latent: 9.9916e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 2.1927 - loss_reco: 2.1927 - loss_latent: 9.9483e-08\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1890 - loss_reco: 2.1890 - loss_latent: 1.0937e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 2.1925 - loss_reco: 2.1925 - loss_latent: 1.0615e-07\n",
      "Epoch 98/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1973 - loss_reco: 2.1973 - loss_latent: 5.8350e-08WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 2.1815 - loss_reco: 2.1815 - loss_latent: 7.8905e-08\n",
      "Epoch 99/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1859 - loss_reco: 2.1859 - loss_latent: 2.9614e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 2.1914 - loss_reco: 2.1914 - loss_latent: 2.7475e-07\n",
      "Epoch 100/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1896 - loss_reco: 2.1896 - loss_latent: 3.7472e-07WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,loss_reco,loss_latent,lr\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 2.1882 - loss_reco: 2.1882 - loss_latent: 3.5522e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1ca0586670>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, verbose=1)]\n",
    "gcnvae.fit(particles_bg, A_bg, epochs=100, batch_size=128,callbacks=callbacks) # validation_split=0.25, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gcn_variational_auto_encoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_, particles_bg_test, A_bg_test, A_tilde_bg_test = prepare_data(filename_bg,3000,4000)\n",
    "features_out_bg_test, z_bg_test, z_mean_bg_test, z_log_var_bg_test = gcnvae((particles_bg_test, A_bg_test))\n",
    "features_out_bg_test = features_out_bg_test.numpy().astype('float32')\n",
    "loss_bg = threeD_loss(particles_bg_test.astype('float32'),features_out_bg_test).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal\n",
    "#filename_sig = 'Ato4l_lepFilter_13TeV.h5'\n",
    "#filename_sig='leptoquark_LOWMASS_lepFilter_13TeV.h5'\n",
    "filename_sig = 'hToTauTau_13TeV_PU20.h5'\n",
    "nodes_n, feat_sz, particles_sig, A_sig, A_tilde_sig = prepare_data(filename_sig)\n",
    "\n",
    "features_out_sig, z_sig, z_mean_sig, z_log_var_sig = gcnvae((particles_sig, A_sig))\n",
    "features_out_sig = features_out_sig.numpy().astype('float32')\n",
    "loss_signal = threeD_loss(particles_sig.astype('float32'),features_out_sig).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_score = np.max(np.max(loss_bg))#,np.max(loss_bg_dist))\n",
    "# plot BG\n",
    "plt.figure()\n",
    "plt.hist(loss_bg, bins=100, label='BG', density=True, range=(0, max_score), \n",
    "         histtype='step', fill=False, linewidth=1.5,color='g')\n",
    "plt.hist(loss_signal, bins=100, label='SIG', density=True, range=(0, max_score), \n",
    "         histtype='step', fill=False, linewidth=1.5,color='r')\n",
    "#plt.semilogy()\n",
    "plt.xlabel(\"AE Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5611715"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_signal.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1979175"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_bg.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
