{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import tqdm\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import inspect\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import Data, DataLoader, DataListLoader\n",
    "from torch_geometric.nn import EdgeConv, global_mean_pool, DataParallel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data,Dataset\n",
    "from torch_scatter import scatter_mean, scatter\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "from torch_geometric.nn import MetaLayer, EdgeConv, global_mean_pool, DynamicEdgeConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "deta_jj = 1.4\n",
    "jPt = 400\n",
    "\n",
    "def xyze_to_eppt(constituents):\n",
    "    ''' converts an array [N x 100, 4] of particles\n",
    "from px, py, pz, E to eta, phi, pt (mass omitted)\n",
    "    '''\n",
    "    PX, PY, PZ, E = range(4)\n",
    "    pt = np.sqrt(np.float_power(constituents[:,PX], 2) + np.float_power(constituents[:,PY], 2), dtype='float32') # numpy.float16 dtype -> float power to avoid overflow\n",
    "    eta = np.arcsinh(np.divide(constituents[:,PZ], pt, out=np.zeros_like(pt), where=pt!=0.), dtype='float32')\n",
    "    phi = np.arctan2(constituents[:,PY], constituents[:,PX], dtype='float32')\n",
    "\n",
    "    return np.stack([pt, eta, phi], axis=1)\n",
    "\n",
    "side = True\n",
    "to_train = True\n",
    "\n",
    "datas = []\n",
    "for i_e in range(1000):\n",
    "    if to_train: \n",
    "        if file_bg['truth_label'][i_e]!=0 : #train only on QCD\n",
    "            continue \n",
    "    if side :\n",
    "        if not (file_bg[\"jet_kinematics\"][i_e,1] > deta_jj):\n",
    "            continue\n",
    "    else : \n",
    "        if not (file_bg[\"jet_kinematics\"][i_e,1] < deta_jj):\n",
    "            continue\n",
    "    for i_j in range(2): #each event has 2 jets\n",
    "        pf_cands = np.array(file_bg[\"jet{}_PFCands\".format(i_j+1)][i_e])\n",
    "        pf_pt_eta_phi = xyze_to_eppt(pf_cands)\n",
    "        n_particles = int(np.sum(pf_pt_eta_phi[:,0]!=0)) #if pt!=0\n",
    "        particles = np.zeros((n_particles, 7)) #px,py,pz,E, pt, eta, phi = 7\n",
    "        #particles = np.dstack((pf_cands[0:n_particles,:],np.array(pf_pt_eta_phi[0:n_particles,:])))\n",
    "        particles = np.hstack((pf_cands[0:n_particles,:],np.array(pf_pt_eta_phi[0:n_particles,:])))\n",
    "        pairs = np.stack([[m, n] for (m, n) in itertools.product(range(n_particles),range(n_particles)) if m!=n])\n",
    "        edge_index = torch.tensor(pairs, dtype=torch.long)\n",
    "        edge_index=edge_index.t().contiguous()\n",
    "        # save particles as node attributes and target\n",
    "        x = torch.tensor(particles, dtype=torch.float)\n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "        datas.append([data])\n",
    "datas = sum(datas,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_present_constit(x,n):\n",
    "    return x[0:n,:] \n",
    "\n",
    "def concat_features(feats_1,feats_2):\n",
    "    return np.hstack((feats_1[:,:],feats_2[:,:]))\n",
    "\n",
    "class GraphDataset(Dataset):  ####inherits from pytorch geometric Dataset (not just pytroch)\n",
    "    def __init__(self, root, transform=None, pre_transform=None,\n",
    "                 n_events=-1,n_jets=10e3, side_reg=1, features='xyzeptep',n_proc=1):\n",
    "        \"\"\"\n",
    "        Initialize parameters of graph dataset\n",
    "        Args:\n",
    "            root (str): dir path\n",
    "            n_events (int): how many events to process (-1=all in a file (there is a max))\n",
    "            n_jets (int) : how many total jets to use\n",
    "            side_reg (bool):true or false, side region for training, otherwise for testing on signal \n",
    "            n_proc (int): number of processes to split into\n",
    "            features (str): (px, py, pz) or relative (pt, eta, phi)\n",
    "        \"\"\"\n",
    "        max_events = int(1.1e6)\n",
    "        self.n_events = max_events if n_events==-1 else n_events\n",
    "        self.n_jets = int(n_jets)\n",
    "        self.side_reg = side_reg\n",
    "        self.n_proc = n_proc\n",
    "        self.chunk_size = self.n_events // self.n_proc\n",
    "        self.features = features\n",
    "        self.dEtaJJ = 1.4\n",
    "        self.jPt = 400\n",
    "        self.jet_kin_names = ['mJJ', 'DeltaEtaJJ', 'j1Pt', 'j1Eta', 'j1Phi',\\\n",
    "                                        'j1M', 'j2Pt', 'j2Eta', 'j2Phi', 'j2M', 'j3Pt', 'j3Eta', 'j3Phi', 'j3M']\n",
    "        self.pf_kin_names = ['px','py','pz','E']\n",
    "        self.pf_cands, self.jet_prop = self.read_events()   \n",
    "\n",
    "        \n",
    "        super(GraphDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        self.input_files = sorted(glob.glob(self.raw_dir+'/*.root'))\n",
    "        return [f.split('/')[-1] for f in self.input_files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_jets\n",
    "  \n",
    "    def xyze_to_ptep(self,constituents):\n",
    "        ''' converts an array [N x 100, 4] of particles\n",
    "from px, py, pz, E to eta, phi, pt (mass omitted)\n",
    "    '''\n",
    "        PX = self.pf_kin_names.index('px')\n",
    "        PY = self.pf_kin_names.index('py')\n",
    "        PZ = self.pf_kin_names.index('pz')\n",
    "        E = self.pf_kin_names.index('E')\n",
    "        pt = np.sqrt(np.float_power(constituents[:,:,PX], 2) + np.float_power(constituents[:,:,PY], 2), dtype='float32') # numpy.float16 dtype -> float power to avoid overflow\n",
    "        eta = np.arcsinh(np.divide(constituents[:,:,PZ], pt, out=np.zeros_like(pt), where=pt!=0.), dtype='float32')\n",
    "        phi = np.arctan2(constituents[:,:,PY], constituents[:,:,PX], dtype='float32')\n",
    "        return np.stack([pt, eta, phi], axis=2)\n",
    "\n",
    "\n",
    "\n",
    "    def read_events(self):\n",
    "        \n",
    "        #Data Samples\n",
    "        DATA_PATH = '/eos/cms/store/group/phys_b2g/CASE/h5_files/full_run2/BB_UL_MC_small_v2/'\n",
    "        TRAIN_NAME = 'BB_batch0.h5'\n",
    "        filename_bg = DATA_PATH + TRAIN_NAME \n",
    "        in_file = h5py.File(filename_bg, 'r') \n",
    "        jet_kin = np.array(in_file[\"jet_kinematics\"])\n",
    "        truth = np.array(in_file[\"truth_label\"])\n",
    "\n",
    "        j1Pt_mask = (jet_kin[:,self.jet_kin_names.index('j1Pt')] > self.jPt)\n",
    "        j2Pt_mask = (jet_kin[:,self.jet_kin_names.index('j2Pt')] > self.jPt)\n",
    "        full_mask = j1Pt_mask & j2Pt_mask\n",
    "        if self.side_reg : \n",
    "            full_mask = full_mask & (jet_kin[:,self.jet_kin_names.index('DeltaEtaJJ')] > self.dEtaJJ)\n",
    "        else : \n",
    "            full_mask = full_mask & (jet_kin[:,self.jet_kin_names.index('DeltaEtaJJ')] < self.dEtaJJ)\n",
    "\n",
    "        #Apply mask on jet kinematics, truth and pf cands\n",
    "        jet_kin = jet_kin[full_mask][0:self.n_jets]\n",
    "        truth = truth[full_mask][0:self.n_jets]\n",
    "        jet_const = [np.array(in_file[\"jet1_PFCands\"])[full_mask][0:self.n_jets],np.array(in_file[\"jet2_PFCands\"])[full_mask][0:self.n_jets]]\n",
    "                \n",
    "\n",
    "        pf_out_list = []\n",
    "        jet_prop_list = []\n",
    "\n",
    "        for i_j in range(2): #each event has 2 jets\n",
    "            pf_xyze = jet_const[i_j]\n",
    "            pf_ptep = self.xyze_to_ptep(pf_xyze)\n",
    "            n_particles = np.sum(pf_xyze[:,:,self.pf_kin_names.index('E')]!=0,axis=1) #E is 3rd \n",
    "            pf_xyze_out = list(map(get_present_constit,pf_xyze,n_particles))\n",
    "            pf_ptep_out = list(map(get_present_constit,pf_ptep,n_particles))\n",
    "            pf_tot_out = list(map(concat_features,pf_xyze_out,pf_ptep_out))\n",
    "            pf_out_list.append(pf_tot_out)\n",
    "\n",
    "            n_jet_feats = 6\n",
    "            jet_prop = np.zeros((len(pf_tot_out),n_jet_feats))\n",
    "            jet_prop[:,0] = n_particles\n",
    "            for i_f,f_name in enumerate('M,Pt,Eta,Phi'.split(',')):\n",
    "                jet_prop[:,i_f+1] = jet_kin[:,self.jet_kin_names.index('j{}{}'.format(i_j+1,f_name))]\n",
    "            jet_prop[:,n_jet_feats-1] = truth[:,0]\n",
    "            jet_prop_list.append(jet_prop)\n",
    "            \n",
    "        #return list of pf particles, and list of global jet properties\n",
    "        return sum(pf_out_list, []),np.vstack((jet_prop_list[0],jet_prop_list[1]))      \n",
    "                 \n",
    "\n",
    "    def get(self,idx):\n",
    "        '''Yields one data graph'''\n",
    "        #pf_cands, jet_prop = self.read_events()  #if done like this, it will process the data each time - insane . Has to be rewritten/rethought with generator.\n",
    "        \n",
    "        i_evt = idx\n",
    "        #for i_evt in range(len(pf_cands)):\n",
    "        n_particles = self.pf_cands[i_evt].shape[0]\n",
    "        pairs = np.stack([[m, n] for (m, n) in itertools.product(range(n_particles),range(n_particles)) if m!=n])\n",
    "        edge_index = torch.tensor(pairs, dtype=torch.long)\n",
    "        edge_index=edge_index.t().contiguous()\n",
    "        # save particles as node attributes and target\n",
    "        x = torch.tensor(self.pf_cands[i_evt], dtype=torch.float)\n",
    "        u = torch.tensor(self.jet_prop[i_evt,:], dtype=torch.float)\n",
    "        data = Data(x=x, edge_index=edge_index,u=torch.unsqueeze(u, 0))\n",
    "        return data\n",
    "    \n",
    "    def return_inmemory_data(self):\n",
    "        datas = []\n",
    "        for i_evt in range(self.n_jets):\n",
    "            n_particles = self.pf_cands[i_evt].shape[0]\n",
    "            pairs = np.stack([[m, n] for (m, n) in itertools.product(range(n_particles),range(n_particles)) if m!=n])\n",
    "            edge_index = torch.tensor(pairs, dtype=torch.long)\n",
    "            edge_index=edge_index.t().contiguous()\n",
    "            # save particles as node attributes and target\n",
    "            x = torch.tensor(self.pf_cands[i_evt], dtype=torch.float)\n",
    "            u = torch.tensor(self.jet_prop[i_evt,:], dtype=torch.float)\n",
    "            data = Data(x=x, edge_index=edge_index,u=torch.unsqueeze(u, 0))\n",
    "            datas.append(data)\n",
    "        return datas\n",
    "        \n",
    "        \n",
    "data_dir = '/eos/user/n/nchernya/MLHEP/AnomalyDetection/ADgvae/output_models/pytroch/'\n",
    "dataset = GraphDataset(root=data_dir,n_jets=1000)\n",
    "    \n",
    "use_generator = False\n",
    "if use_generator:\n",
    "    validation_split = 0.2\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    if dataset_size > 2:\n",
    "        split = int(np.floor(validation_split * dataset_size))\n",
    "    else: \n",
    "        split = 1\n",
    "    print(dataset_size,split)\n",
    "    random_seed= 1001\n",
    "\n",
    "    train_subset, val_subset = torch.utils.data.random_split(dataset, [dataset_size - split, split],\n",
    "                                                             generator=torch.Generator().manual_seed(random_seed))\n",
    "    print(\"train subset dim:\", len(train_subset))\n",
    "    print(\"validation subset dim\", len(val_subset))\n",
    "    dataloaders = {\n",
    "        'train':  DataLoader(train_subset, batch_size=128, shuffle=True),\n",
    "        'val':   DataLoader(val_subset, batch_size=128, shuffle=True)\n",
    "    }\n",
    "    print(\"train_dataloader dim:\", len(dataloaders['train']))\n",
    "    print(\"val dataloader dim:\", len(dataloaders['val']))\n",
    "else : \n",
    "    in_memory_datas = dataset.return_inmemory_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardizer:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        :param data: torch tensor\n",
    "        \"\"\"\n",
    "        self.mean = torch.mean(data, dim=0)\n",
    "        self.std = torch.std(data, dim=0)\n",
    "\n",
    "    def transform(self, data):\n",
    "        return (data - self.mean) / self.std\n",
    "\n",
    "    def inverse_transform(self, data, log_pt=False):\n",
    "        \"\"\"\n",
    "        :param data: torch tensor\n",
    "        :param log_pt: undo log transformation on pt\n",
    "        \"\"\"\n",
    "        inverse = (data * self.std) + self.mean\n",
    "        if log_pt:\n",
    "            inverse[:,0] = (10 ** inverse[:,0]) - 1\n",
    "        return inverse\n",
    "\n",
    "def standardize(train_dataset,log_pt=False):\n",
    "    \"\"\"\n",
    "    standardize dataset and return scaler for inversion\n",
    "    :param train_dataset: list of Data objects\n",
    "    :param valid_dataset: list of Data objects\n",
    "    :param test_dataset: list of Data objects\n",
    "    :param log_pt: log pt before standardization\n",
    "    :return scaler: sklearn StandardScaler\n",
    "    \"\"\"\n",
    "    train_x = torch.cat([d.x for d in train_dataset])\n",
    "    if log_pt:\n",
    "        train_x[:,0] = torch.log(train_x[:,0] + 1)\n",
    "\n",
    "    scaler = Standardizer()\n",
    "    scaler.fit(train_x)\n",
    "    for d in train_dataset:\n",
    "        d.x[:,:] = scaler.transform(d.x)\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader dim: 8\n"
     ]
    }
   ],
   "source": [
    "#scaler = standardize(train_subset) # I dont think that this works for the dataset implementation as it is done now\n",
    "scaler = standardize(in_memory_datas) \n",
    "\n",
    "dataloaders = {\n",
    "    'train':  DataLoader(in_memory_datas, batch_size=128, shuffle=True)\n",
    "    }\n",
    "print(\"train_dataloader dim:\", len(dataloaders['train']))\n",
    "\n",
    "#dataset.get(0).u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Model definitions.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_scatter import scatter_mean, scatter\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "from torch_geometric.nn import MetaLayer, EdgeConv, global_mean_pool, DynamicEdgeConv\n",
    "\n",
    "\n",
    "# GNN AE using EdgeConv (mean aggregation graph operation). Basic GAE model.\n",
    "class EdgeNet(nn.Module):\n",
    "    def __init__(self, input_dim=7, output_dim=4, big_dim=32, hidden_dim=2, aggr='mean'):\n",
    "        super(EdgeNet, self).__init__()\n",
    "        encoder_nn = nn.Sequential(nn.Linear(2*(input_dim), big_dim),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(big_dim, big_dim),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(big_dim, hidden_dim),\n",
    "                               nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        decoder_nn = nn.Sequential(nn.Linear(2*(hidden_dim), big_dim),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(big_dim, big_dim),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(big_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "        self.encoder = EdgeConv(nn=encoder_nn,aggr=aggr)\n",
    "        self.decoder = EdgeConv(nn=decoder_nn,aggr=aggr)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.batchnorm(data.x)\n",
    "        x = self.encoder(x,data.edge_index)\n",
    "        x = self.decoder(x,data.edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loader, total, batch_size, loss_ftn_obj):\n",
    "    model.train()\n",
    "\n",
    "    sum_loss = 0.\n",
    "    t = tqdm.tqdm(enumerate(loader),total=total/batch_size)\n",
    "    for i,data in t:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_loss, batch_output = forward_loss(model, data, loss_ftn_obj, device, multi_gpu=False)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss = batch_loss.item()\n",
    "        sum_loss += batch_loss\n",
    "        t.set_description('train loss = %.7f' % batch_loss)\n",
    "        t.refresh() # to show immediately the update\n",
    "\n",
    "    return sum_loss / (i+1)\n",
    "\n",
    "\n",
    "# helper to perform correct loss\n",
    "def forward_loss(model, data, loss_ftn_obj, device, multi_gpu=False):\n",
    "    \n",
    "    if not multi_gpu:\n",
    "        data = data.to(device)\n",
    "\n",
    "    if 'emd_loss' in loss_ftn_obj.name or loss_ftn_obj.name == 'chamfer_loss' or loss_ftn_obj.name == 'hungarian_loss':\n",
    "        batch_output = model(data)\n",
    "        if multi_gpu:\n",
    "            data = Batch.from_data_list(data).to(device)\n",
    "        y = data.x\n",
    "        batch = data.batch\n",
    "        batch_loss = loss_ftn_obj.loss_ftn(batch_output, y, batch)\n",
    "\n",
    "    elif loss_ftn_obj.name == 'emd_in_forward':\n",
    "        _, batch_loss = model(data)\n",
    "        batch_loss = batch_loss.mean()\n",
    "\n",
    "    elif loss_ftn_obj.name == 'vae_loss':\n",
    "        batch_output, mu, log_var = model(data)\n",
    "        y = torch.cat([d.x for d in data]).to(device) if multi_gpu else data.x\n",
    "        y = y.contiguous()\n",
    "        batch_loss = loss_ftn_obj.loss_ftn(batch_output, y, mu, log_var)\n",
    "\n",
    "    else:\n",
    "        batch_output = model(data)\n",
    "        y = torch.cat([d.x for d in data]).to(device) if multi_gpu else data.x\n",
    "        y = y.contiguous()\n",
    "        batch_loss = loss_ftn_obj.loss_ftn(batch_output, y)\n",
    "\n",
    "    return batch_loss, batch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "multi_gpu = False #torch.cuda.device_count()>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyze_to_ptetaphi_torch(y):\n",
    "    ''' converts an array [N x 100, 4] of particles\n",
    "from px, py, pz, E to pt,eta, phi\n",
    "    '''\n",
    "    PX, PY, PZ, E = range(4)\n",
    "    pt = torch.sqrt(torch.pow(y[:,PX], 2) + torch.pow(y[:,PY], 2)) \n",
    "    eta = torch.asinh(torch.where(pt < 10e-5, torch.zeros_like(pt), torch.div(y[:,PZ], pt)))\n",
    "    phi = torch.atan2(y[:,PY], y[:,PX])\n",
    "\n",
    "    relu =  m = nn.ReLU() #inplace=True\n",
    "    y_E_trimmed = relu(y[:,-1]) #trimming E\n",
    "    y_pt_trimmed = relu(pt) #trimming pt\n",
    "    full_y = torch.stack((y[:,0],y[:,1],y[:,2],y_E_trimmed,y_pt_trimmed,eta,phi), dim=1)\n",
    "\n",
    "    return full_y\n",
    "\n",
    "\n",
    "class LossFunction:\n",
    "    def __init__(self, lossname, device=torch.device('cuda:0')):\n",
    "        loss = getattr(self, lossname)\n",
    "        self.name = lossname\n",
    "        self.loss_ftn = loss\n",
    "        self.device = device\n",
    "        \n",
    "    def mse(self, x, y):\n",
    "        return F.mse_loss(x, y, reduction='mean')\n",
    "    \n",
    "    def mse_coordinates(self, y,x): #for some reason convension is : out,in\n",
    "        #From px,py,pz,E get pt, eta, phi (do not predict them)\n",
    "        #x is px,py,pz,E,pt,eta,phi\n",
    "        #y is px,py,pz,E\n",
    "        full_y = xyze_to_ptetaphi_torch(y)\n",
    "        return self.mse(x,full_y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeNet(\n",
       "  (batchnorm): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (encoder): EdgeConv(nn=Sequential(\n",
       "    (0): Linear(in_features=14, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (5): ReLU()\n",
       "  ))\n",
       "  (decoder): EdgeConv(nn=Sequential(\n",
       "    (0): Linear(in_features=4, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=7, bias=True)\n",
       "  ))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss\n",
    "#loss_ftn_obj = LossFunction('mse_coordinates', device=device)\n",
    "loss_ftn_obj = LossFunction('mse', device=device)\n",
    "\n",
    "# model\n",
    "input_dim = 7\n",
    "output_dim = 7#4\n",
    "big_dim = 32\n",
    "hidden_dim = 2\n",
    "model = EdgeNet(input_dim=input_dim,output_dim=output_dim, big_dim=big_dim, hidden_dim=hidden_dim)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 10e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=4, threshold=1e-6)\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.7475386: : 8it [00:01,  6.43it/s]                          \n",
      "train loss = 0.7425943:  38%|███▊      | 3/7.8125 [00:00<00:00, 21.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Training Loss:   0.9179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.7787465: : 8it [00:00, 21.64it/s]                          \n",
      "train loss = 0.7150579:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Training Loss:   0.7511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.5570742: : 8it [00:00, 24.15it/s]                          \n",
      "train loss = 0.4899089:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Training Loss:   0.6515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.4190300: : 8it [00:00, 23.99it/s]                          \n",
      "train loss = 0.3580547:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Training Loss:   0.4946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.2555426: : 8it [00:00, 23.93it/s]                          \n",
      "train loss = 0.3751278:  38%|███▊      | 3/7.8125 [00:00<00:00, 22.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Training Loss:   0.3957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.3283700: : 8it [00:00, 23.50it/s]                          \n",
      "train loss = 0.3020281:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Training Loss:   0.3287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.2315729: : 8it [00:00, 22.49it/s]                          \n",
      "train loss = 0.1960796:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Training Loss:   0.2926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.2699398: : 8it [00:00, 23.99it/s]                          \n",
      "train loss = 0.1949106:  38%|███▊      | 3/7.8125 [00:00<00:00, 22.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Training Loss:   0.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.2019417: : 8it [00:00, 22.41it/s]                          \n",
      "train loss = 0.2105487:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Training Loss:   0.2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1574364: : 8it [00:00, 23.71it/s]                          \n",
      "train loss = 0.1479566:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Training Loss:   0.1830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1403333: : 8it [00:00, 24.18it/s]                          \n",
      "train loss = 0.0840258:  38%|███▊      | 3/7.8125 [00:00<00:00, 21.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss:   0.1557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1533939: : 8it [00:00, 22.16it/s]                          \n",
      "train loss = 0.1158177:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Training Loss:   0.1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0904480: : 8it [00:00, 23.95it/s]                          \n",
      "train loss = 0.1025347:  38%|███▊      | 3/7.8125 [00:00<00:00, 21.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Training Loss:   0.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1160549: : 8it [00:00, 22.89it/s]                          \n",
      "train loss = 0.1129461:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Training Loss:   0.1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1016909: : 8it [00:00, 24.41it/s]                          \n",
      "train loss = 0.1011642:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Training Loss:   0.1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0907081: : 8it [00:00, 23.06it/s]                          \n",
      "train loss = 0.0983043:  38%|███▊      | 3/7.8125 [00:00<00:00, 22.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Training Loss:   0.1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0970521: : 8it [00:00, 23.65it/s]                          \n",
      "train loss = 0.0857799:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Training Loss:   0.1041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1048030: : 8it [00:00, 23.42it/s]                          \n",
      "train loss = 0.0797524:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Training Loss:   0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0893670: : 8it [00:00, 25.19it/s]                          \n",
      "train loss = 0.0710639:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Training Loss:   0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1018090: : 8it [00:00, 24.25it/s]                          \n",
      "train loss = 0.0858047:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Training Loss:   0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0585775: : 8it [00:00, 25.28it/s]                          \n",
      "train loss = 0.0708721:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Training Loss:   0.0765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0677299: : 8it [00:00, 25.21it/s]                          \n",
      "train loss = 0.0800082:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Training Loss:   0.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0624596: : 8it [00:00, 24.86it/s]                          \n",
      "train loss = 0.0855809:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Training Loss:   0.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0916473: : 8it [00:00, 25.03it/s]                          \n",
      "train loss = 0.0642789:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Training Loss:   0.0837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1198972: : 8it [00:00, 23.96it/s]                          \n",
      "train loss = 0.0844235:  38%|███▊      | 3/7.8125 [00:00<00:00, 22.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Training Loss:   0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0559634: : 8it [00:00, 22.84it/s]                          \n",
      "train loss = 0.0830481:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Training Loss:   0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0779901: : 8it [00:00, 25.14it/s]                          \n",
      "train loss = 0.0699527:  38%|███▊      | 3/7.8125 [00:00<00:00, 21.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Training Loss:   0.0750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0624757: : 8it [00:00, 22.68it/s]                          \n",
      "train loss = 0.0514325:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Training Loss:   0.0766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0624259: : 8it [00:00, 25.20it/s]                          \n",
      "train loss = 0.0502170:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Training Loss:   0.0740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0683164: : 8it [00:00, 23.32it/s]                          \n",
      "train loss = 0.0808447:  38%|███▊      | 3/7.8125 [00:00<00:00, 26.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Training Loss:   0.0758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0935838: : 8it [00:00, 25.16it/s]                          \n",
      "train loss = 0.0694738:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Training Loss:   0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0901861: : 8it [00:00, 25.21it/s]                          \n",
      "train loss = 0.0768575:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Training Loss:   0.0768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0932597: : 8it [00:00, 25.18it/s]                          \n",
      "train loss = 0.0678616:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Training Loss:   0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0943939: : 8it [00:00, 25.18it/s]                          \n",
      "train loss = 0.0754122:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Training Loss:   0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0963378: : 8it [00:00, 25.10it/s]                          \n",
      "train loss = 0.0537468:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Training Loss:   0.0704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0722131: : 8it [00:00, 25.11it/s]                          \n",
      "train loss = 0.0610189:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Training Loss:   0.0629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0501374: : 8it [00:00, 25.02it/s]                          \n",
      "train loss = 0.0785490:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Training Loss:   0.0637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0858953: : 8it [00:00, 24.46it/s]                          \n",
      "train loss = 0.0989793:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Training Loss:   0.0733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0605864: : 8it [00:00, 21.74it/s]                          \n",
      "train loss = 0.0528818:  38%|███▊      | 3/7.8125 [00:00<00:00, 21.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Training Loss:   0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0605728: : 8it [00:00, 21.91it/s]                          \n",
      "train loss = 0.0548394:  38%|███▊      | 3/7.8125 [00:00<00:00, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Training Loss:   0.0670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0859439: : 8it [00:00, 21.91it/s]                          \n",
      "train loss = 0.0734868:  38%|███▊      | 3/7.8125 [00:00<00:00, 21.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Training Loss:   0.0611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0515118: : 8it [00:00, 22.03it/s]                          \n",
      "train loss = 0.0520447:  38%|███▊      | 3/7.8125 [00:00<00:00, 22.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Training Loss:   0.0760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1043358: : 8it [00:00, 21.97it/s]                          \n",
      "train loss = 0.0478440:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Training Loss:   0.0717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0788044: : 8it [00:00, 25.14it/s]                          \n",
      "train loss = 0.0610387:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Training Loss:   0.0641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0675502: : 8it [00:00, 25.16it/s]                          \n",
      "train loss = 0.0473323:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Training Loss:   0.0636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0469295: : 8it [00:00, 25.03it/s]                          \n",
      "train loss = 0.0462295:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Training Loss:   0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0437600: : 8it [00:00, 24.25it/s]                          \n",
      "train loss = 0.0517046:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Training Loss:   0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0571039: : 8it [00:00, 22.81it/s]                          \n",
      "train loss = 0.0823893:  38%|███▊      | 3/7.8125 [00:00<00:00, 22.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Training Loss:   0.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0577339: : 8it [00:00, 24.16it/s]                          \n",
      "train loss = 0.0588257:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Training Loss:   0.0571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0697363: : 8it [00:00, 24.26it/s]                          \n",
      "train loss = 0.0493295:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Training Loss:   0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0552601: : 8it [00:00, 22.21it/s]                          \n",
      "train loss = 0.0676070:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Training Loss:   0.0603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0514778: : 8it [00:00, 25.12it/s]                          \n",
      "train loss = 0.0388598:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, Training Loss:   0.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0512487: : 8it [00:00, 25.28it/s]                          \n",
      "train loss = 0.0445996:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52, Training Loss:   0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0500326: : 8it [00:00, 25.24it/s]                          \n",
      "train loss = 0.0370677:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53, Training Loss:   0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0513884: : 8it [00:00, 25.32it/s]                          \n",
      "train loss = 0.0626720:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54, Training Loss:   0.0465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0465760: : 8it [00:00, 25.32it/s]                          \n",
      "train loss = 0.0378897:  38%|███▊      | 3/7.8125 [00:00<00:00, 22.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55, Training Loss:   0.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0751434: : 8it [00:00, 23.18it/s]                          \n",
      "train loss = 0.0597783:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, Training Loss:   0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0511368: : 8it [00:00, 24.51it/s]                          \n",
      "train loss = 0.0522224:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57, Training Loss:   0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0572367: : 8it [00:00, 24.60it/s]                          \n",
      "train loss = 0.0576026:  38%|███▊      | 3/7.8125 [00:00<00:00, 22.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58, Training Loss:   0.0518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0721417: : 8it [00:00, 23.52it/s]                          \n",
      "train loss = 0.0508808:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59, Training Loss:   0.0520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0688027: : 8it [00:00, 24.26it/s]                          \n",
      "train loss = 0.0388669:  38%|███▊      | 3/7.8125 [00:00<00:00, 23.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Training Loss:   0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0372685: : 8it [00:00, 24.47it/s]                          \n",
      "train loss = 0.0414363:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61, Training Loss:   0.0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0362583: : 8it [00:00, 25.14it/s]                          \n",
      "train loss = 0.0717653:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62, Training Loss:   0.0514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0442414: : 8it [00:00, 25.28it/s]                          \n",
      "train loss = 0.0474826:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63, Training Loss:   0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0471001: : 8it [00:00, 25.27it/s]                          \n",
      "train loss = 0.0422874:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64, Training Loss:   0.0477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0549597: : 8it [00:00, 25.32it/s]                          \n",
      "train loss = 0.0499493:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65, Training Loss:   0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1526406: : 8it [00:00, 25.31it/s]                          \n",
      "train loss = 0.1190098:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, Training Loss:   0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0679528: : 8it [00:00, 25.27it/s]                          \n",
      "train loss = 0.0481311:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67, Training Loss:   0.0639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0472118: : 8it [00:00, 25.35it/s]                          \n",
      "train loss = 0.0410708:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68, Training Loss:   0.0630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0416030: : 8it [00:00, 25.31it/s]                          \n",
      "train loss = 0.0450964:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69, Training Loss:   0.0445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0320823: : 8it [00:00, 25.30it/s]                          \n",
      "train loss = 0.0451299:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70, Training Loss:   0.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0461104: : 8it [00:00, 25.43it/s]                          \n",
      "train loss = 0.0544953:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71, Training Loss:   0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0361238: : 8it [00:00, 25.35it/s]                          \n",
      "train loss = 0.0383699:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72, Training Loss:   0.0493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0359280: : 8it [00:00, 25.36it/s]                          \n",
      "train loss = 0.0463924:  38%|███▊      | 3/7.8125 [00:00<00:00, 25.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, Training Loss:   0.0432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0551582: : 8it [00:00, 25.32it/s]                          \n",
      "train loss = 0.0575165:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74, Training Loss:   0.0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0424429: : 8it [00:00, 25.33it/s]                          \n",
      "train loss = 0.0484901:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75, Training Loss:   0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0347292: : 8it [00:00, 25.26it/s]                          \n",
      "train loss = 0.0275179:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76, Training Loss:   0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0486112: : 8it [00:00, 24.60it/s]                          \n",
      "train loss = 0.0529840:  38%|███▊      | 3/7.8125 [00:00<00:00, 22.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77, Training Loss:   0.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0308493: : 8it [00:00, 24.09it/s]                          \n",
      "train loss = 0.0658534:  38%|███▊      | 3/7.8125 [00:00<00:00, 24.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78, Training Loss:   0.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0401981: : 8it [00:00, 25.08it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79, Training Loss:   0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "n_epochs = 80\n",
    "stale_epochs = 0\n",
    "loss = 999999\n",
    "train_losses = []\n",
    "for epoch in range(0, n_epochs):\n",
    "    #loss = train(model, optimizer, loader, len(datas), 128, loss_ftn_obj)\n",
    "    loss = train(model, optimizer, dataloaders['train'], len(dataloaders['train'].dataset), dataloaders['train'].batch_size, loss_ftn_obj)\n",
    "    train_losses.append(loss)\n",
    "    print('Epoch: {:02d}, Training Loss:   {:.4f}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def gen_in_out(model, loader, device):\n",
    "    model.eval()\n",
    "    input_fts = []\n",
    "    reco_fts = []\n",
    "\n",
    "    for t in loader:\n",
    "        if isinstance(t, list):\n",
    "            for d in t:\n",
    "                input_fts.append(d.x)\n",
    "        else:\n",
    "            input_fts.append(t.x)\n",
    "            t.to(device)\n",
    "\n",
    "        reco_out = model(t)\n",
    "        if isinstance(reco_out, tuple):\n",
    "            reco_out = reco_out[0]\n",
    "        reco_fts.append(reco_out.cpu().detach())\n",
    "\n",
    "    input_fts = torch.cat(input_fts)\n",
    "    reco_fts = torch.cat(reco_fts)\n",
    "    return input_fts, reco_fts\n",
    "\n",
    "def plot_reco_for_loader(model, loader, device, scaler, inverse_scale, model_fname, save_dir, feature_format):\n",
    "    input_fts, reco_fts = gen_in_out(model, loader, device)\n",
    "    if inverse_scale:\n",
    "        input_fts = scaler.inverse_transform(input_fts)\n",
    "        reco_fts = scaler.inverse_transform(reco_fts)\n",
    "    plot_reco_difference(input_fts, reco_fts, model_fname, save_dir, feature_format)\n",
    "\n",
    "    \n",
    "def plot_reco_difference(input_fts, reco_fts, model_fname, save_path, feature='hadronic'):\n",
    "    \"\"\"\n",
    "    Plot the difference between the autoencoder's reconstruction and the original input\n",
    "    Args:\n",
    "        input_fts (numpy array): the original features of the particles\n",
    "        reco_fts (numpy array): the reconstructed features\n",
    "        model_fname (str): name of saved model\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(input_fts, torch.Tensor):\n",
    "        input_fts = input_fts.numpy()\n",
    "    if isinstance(reco_fts, torch.Tensor):\n",
    "       # if feature == 'all':\n",
    "       #     reco_fts = xyze_to_ptetaphi_torch(reco_fts)\n",
    "        reco_fts = reco_fts.numpy()\n",
    "\n",
    "        \n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "  #  label = ['$p_x~[GeV]$', '$p_y~[GeV]$', '$p_z~[GeV]$']\n",
    "   # feat = ['px', 'py', 'pz']\n",
    "    label = ['$p_x~[GeV]$', '$p_y~[GeV]$', '$p_z~[GeV]$']\n",
    "    feat = ['px', 'py', 'pz']\n",
    "    if feature == 'hadronic':# or 'standardized':\n",
    "        label = ['$p_T$', '$eta$', '$phi$']\n",
    "        feat = ['pt', 'eta', 'phi']\n",
    "        \n",
    "    if feature == 'all':# or 'standardized':\n",
    "        label = ['$p_x~[GeV]$', '$p_y~[GeV]$', '$p_z~[GeV]$', '$E~[GeV]$','$p_T$', '$eta$', '$phi$']\n",
    "        feat = ['px', 'py', 'pz','E','pt', 'eta', 'phi']\n",
    "        \n",
    "    # make a separate plot for each feature\n",
    "    for i in range(input_fts.shape[1]):\n",
    "        #plt.style.use(hep.style.CMS)\n",
    "        plt.figure(figsize=(10,8))\n",
    "        if feature == 'cartesian':\n",
    "            bins = np.linspace(-20, 20, 101)\n",
    "            if i == 3:  # different bin size for E momentum\n",
    "                bins = np.linspace(-5, 35, 101)\n",
    "        elif feature == 'hadronic':\n",
    "            bins = np.linspace(-2, 2, 101)\n",
    "            if i == 0:  # different bin size for pt rel\n",
    "                bins = np.linspace(-0.05, 0.1, 101)\n",
    "        elif feature == 'all':\n",
    "            bins = np.linspace(-20, 20, 101)\n",
    "            if i > 3:  # different bin size for hadronic coord\n",
    "                bins = np.linspace(-2, 2, 101)\n",
    "            if i == 3:  # different bin size for E momentum\n",
    "                bins = np.linspace(-5, 35, 101)\n",
    "            if i == 4:  # different bin size for pt rel\n",
    "                bins = np.linspace(-2, 10, 101)\n",
    "        else:\n",
    "            bins = np.linspace(-1, 1, 101)\n",
    "        plt.ticklabel_format(useMathText=True)\n",
    "        plt.hist(input_fts[:,i], bins=bins, alpha=0.5, label='Input', histtype='step', lw=5)\n",
    "        plt.hist(reco_fts[:,i], bins=bins, alpha=0.5, label='Output', histtype='step', lw=5)\n",
    "        plt.legend(title='QCD dataset', fontsize='x-large')\n",
    "        plt.xlabel(label[i], fontsize='x-large')\n",
    "        plt.ylabel('Particles', fontsize='x-large')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(osp.join(save_path, feat[i] + '.png'))\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_standardization = True\n",
    "save_dir = '/eos/user/n/nchernya/MLHEP/AnomalyDetection/ADgvae/output_models/pytroch/'\n",
    "plot_reco_for_loader(model, dataloaders['train'], device, scaler, inverse_standardization, 'test_train', osp.join(save_dir, 'reconstruction_post_train', 'train_reco_all_std'), 'all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
