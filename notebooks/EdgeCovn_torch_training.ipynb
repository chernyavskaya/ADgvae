{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import tqdm\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import inspect\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import Data, DataLoader, DataListLoader\n",
    "from torch_geometric.nn import EdgeConv, global_mean_pool, DataParallel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data,Dataset\n",
    "from torch_scatter import scatter_mean, scatter\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "from torch_geometric.nn import MetaLayer, EdgeConv, global_mean_pool, DynamicEdgeConv\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'vande.util.util_plotting' from '/eos/home-n/nchernya/MLHEP/AnomalyDetection/vande/util/util_plotting.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../')))\n",
    "\n",
    "import models_torch.models as models\n",
    "reload(models)\n",
    "import models_torch.losses as losses\n",
    "reload(losses)\n",
    "import utils_torch.scaler\n",
    "reload(utils_torch.scaler)\n",
    "import utils_torch.preprocessing as prepr\n",
    "import utils_torch.plot_util as plot\n",
    "reload(plot)\n",
    "import utils_torch.train_util as train\n",
    "reload(train)\n",
    "import graph_data.graph_data as graph_data\n",
    "reload(graph_data)\n",
    "sys.path.append(os.path.abspath(os.path.join('../../')))\n",
    "import vande.util.util_plotting as vande_plot\n",
    "reload(vande_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/eos/user/n/nchernya/MLHEP/AnomalyDetection/ADgvae/output_models/pytroch/'\n",
    "dataset = graph_data.GraphDataset(root=data_dir,n_jets=1e3)\n",
    "save_dir = '/eos/user/n/nchernya/MLHEP/AnomalyDetection/ADgvae/output_models/pytroch/input_feats/'\n",
    "   \n",
    "use_generator = False\n",
    "if use_generator:\n",
    "    validation_split = 0.2\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    if dataset_size > 2:\n",
    "        split = int(np.floor(validation_split * dataset_size))\n",
    "    else: \n",
    "        split = 1\n",
    "    print(dataset_size,split)\n",
    "    random_seed= 1001\n",
    "\n",
    "    train_subset, val_subset = torch.utils.data.random_split(dataset, [dataset_size - split, split],\n",
    "                                                             generator=torch.Generator().manual_seed(random_seed))\n",
    "    print(\"train subset dim:\", len(train_subset))\n",
    "    print(\"validation subset dim\", len(val_subset))\n",
    "    dataloaders = {\n",
    "        'train':  DataLoader(train_subset, batch_size=128, shuffle=True),\n",
    "        'val':   DataLoader(val_subset, batch_size=128, shuffle=True)\n",
    "    }\n",
    "    print(\"train_dataloader dim:\", len(dataloaders['train']))\n",
    "    print(\"val dataloader dim:\", len(dataloaders['val']))\n",
    "else : \n",
    "    in_memory_datas = dataset.return_inmemory_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_cands,jet_prop = dataset.pf_cands,dataset.jet_prop\n",
    "pf_cands_t = torch.cat([torch.tensor(pf_cands[i], dtype=torch.float) for i in range(len(pf_cands))])\n",
    "#Plot consistuents and jet features prepared for the graph! (but before any normalization)\n",
    "pf_feats = 'px,py,pz,E,pt,eta,phi'.split(',')\n",
    "jet_feats = 'N_constituents,M,Pt,Eta,Phi'.split(',')\n",
    "\n",
    "\n",
    "save_dir = '/eos/user/n/nchernya/MLHEP/AnomalyDetection/ADgvae/output_models/pytroch/input_feats/'\n",
    "vande_plot.plot_features(pf_cands_t.numpy(), pf_feats ,'Normalized' , 'QCD', plotname='{}plot_pf_feats_{}'.format(save_dir,'QCD_side'), legend=['QCD'], ylogscale=True)\n",
    "vande_plot.plot_features(jet_prop[:,0:-1], jet_feats ,'Normalized' , 'QCD', plotname='{}plot_jet_feats_{}'.format(save_dir,'QCD_side'), legend=['QCD'], ylogscale=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader dim: 8\n"
     ]
    }
   ],
   "source": [
    "#scaler = standardize(train_subset) # I dont think that this works for the dataset implementation as it is done now, implement scaler as part of dataset ? \n",
    "scaler = prepr.standardize(in_memory_datas,minmax_idx=[3,4],log_idx=[3,4]) \n",
    "\n",
    "dataloaders = {\n",
    "    'train':  DataLoader(in_memory_datas, batch_size=128, shuffle=True)\n",
    "    }\n",
    "print(\"train_dataloader dim:\", len(dataloaders['train']))\n",
    "\n",
    "#dataset.get(0).u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_cands_norm = torch.cat([torch.tensor(in_memory_datas[i].x, dtype=torch.float) for i in range(len(in_memory_datas))])\n",
    "#Plot consistuents and jet features prepared for the graph! (after normalization)\n",
    "pf_feats = 'px,py,pz,E,pt,eta,phi'.split(',')\n",
    "save_dir = '/eos/user/n/nchernya/MLHEP/AnomalyDetection/ADgvae/output_models/pytroch/input_feats_normalized/'\n",
    "vande_plot.plot_features(pf_cands_norm.numpy(), pf_feats ,'Normalized' , 'QCD', plotname='{}plot_pf_feats_{}'.format(save_dir,'QCD_side'), legend=['QCD'], ylogscale=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "multi_gpu = False #torch.cuda.device_count()>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeNet(\n",
       "  (batchnorm): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (encoder): EdgeConv(nn=Sequential(\n",
       "    (0): Linear(in_features=14, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (5): ReLU()\n",
       "  ))\n",
       "  (decoder): EdgeConv(nn=Sequential(\n",
       "    (0): Linear(in_features=4, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=7, bias=True)\n",
       "  ))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss\n",
    "#loss_ftn_obj = LossFunction('mse_coordinates', device=device)\n",
    "loss_ftn_obj = losses.LossFunction('mse', device=device)\n",
    "\n",
    "# model\n",
    "input_dim = 7\n",
    "output_dim = 7#4\n",
    "big_dim = 32\n",
    "hidden_dim = 2\n",
    "model = models.EdgeNet(input_dim=input_dim,output_dim=output_dim, big_dim=big_dim, hidden_dim=hidden_dim)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 10e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=4, threshold=1e-6)\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.7552591: : 8it [00:07,  1.14it/s]                          \n",
      "train loss = 0.4527319: : 8it [00:00, 40.17it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Training Loss:   0.7019\n",
      "Epoch: 01, Training Loss:   0.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.3188988: : 8it [00:00, 40.51it/s]                          \n",
      "train loss = 0.2936581: : 8it [00:00, 40.21it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Training Loss:   0.4008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss = 0.2665380: : 8it [00:00, 40.48it/s]                          \n",
      "train loss = 0.1912614: : 8it [00:00, 40.27it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Training Loss:   0.3133\n",
      "Epoch: 04, Training Loss:   0.2517\n",
      "Epoch: 05, Training Loss:   0.2081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.2005747: : 8it [00:00, 40.55it/s]                          \n",
      "train loss = 0.1750993: : 8it [00:00, 41.09it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Training Loss:   0.1981\n",
      "Epoch: 07, Training Loss:   0.1687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1348961: : 8it [00:00, 41.06it/s]                          \n",
      "train loss = 0.1428265: : 8it [00:00, 41.19it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Training Loss:   0.1508\n",
      "Epoch: 09, Training Loss:   0.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0976413: : 8it [00:00, 41.12it/s]                          \n",
      "train loss = 0.1216814: : 8it [00:00, 41.17it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss:   0.1154\n",
      "Epoch: 11, Training Loss:   0.1085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1041491: : 8it [00:00, 41.11it/s]                          \n",
      "train loss = 0.1075222: : 8it [00:00, 41.20it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Training Loss:   0.1043\n",
      "Epoch: 13, Training Loss:   0.0984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0828063: : 8it [00:00, 41.21it/s]                          \n",
      "train loss = 0.0884089: : 8it [00:00, 40.59it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Training Loss:   0.1063\n",
      "Epoch: 15, Training Loss:   0.1071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1056228: : 8it [00:00, 40.34it/s]                          \n",
      "train loss = 0.0759086: : 8it [00:00, 40.36it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Training Loss:   0.0961\n",
      "Epoch: 17, Training Loss:   0.0898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0690226: : 8it [00:00, 40.46it/s]                          \n",
      "train loss = 0.0758946: : 8it [00:00, 40.86it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Training Loss:   0.0856\n",
      "Epoch: 19, Training Loss:   0.0905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0777586: : 8it [00:00, 41.05it/s]                          \n",
      "train loss = 0.0633042: : 8it [00:00, 41.21it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Training Loss:   0.0794\n",
      "Epoch: 21, Training Loss:   0.0775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0580424: : 8it [00:00, 41.26it/s]                          \n",
      "train loss = 0.0733966: : 8it [00:00, 41.03it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Training Loss:   0.0677\n",
      "Epoch: 23, Training Loss:   0.0732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0604401: : 8it [00:00, 40.41it/s]                          \n",
      "train loss = 0.0543485: : 8it [00:00, 41.10it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Training Loss:   0.0727\n",
      "Epoch: 25, Training Loss:   0.0647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0635174: : 8it [00:00, 40.95it/s]                          \n",
      "train loss = 0.0778672: : 8it [00:00, 41.40it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Training Loss:   0.0615\n",
      "Epoch: 27, Training Loss:   0.0653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0627833: : 8it [00:00, 41.24it/s]                          \n",
      "train loss = 0.0761069: : 8it [00:00, 40.37it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Training Loss:   0.0655\n",
      "Epoch: 29, Training Loss:   0.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0514720: : 8it [00:00, 41.52it/s]                          \n",
      "train loss = 0.0640080: : 8it [00:00, 41.61it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Training Loss:   0.0678\n",
      "Epoch: 31, Training Loss:   0.0696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0656372: : 8it [00:00, 41.64it/s]                          \n",
      "train loss = 0.0376914: : 8it [00:00, 41.80it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Training Loss:   0.0603\n",
      "Epoch: 33, Training Loss:   0.0550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0491690: : 8it [00:00, 40.44it/s]                          \n",
      "train loss = 0.0651619: : 8it [00:00, 41.61it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Training Loss:   0.0516\n",
      "Epoch: 35, Training Loss:   0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0645894: : 8it [00:00, 41.64it/s]                          \n",
      "train loss = 0.0478077: : 8it [00:00, 41.68it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Training Loss:   0.0573\n",
      "Epoch: 37, Training Loss:   0.0504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.1207584: : 8it [00:00, 41.41it/s]                          \n",
      "train loss = 0.0636649: : 8it [00:00, 41.69it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Training Loss:   0.0632\n",
      "Epoch: 39, Training Loss:   0.0559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0458898: : 8it [00:00, 41.75it/s]                          \n",
      "train loss = 0.0638216: : 8it [00:00, 41.75it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Training Loss:   0.0476\n",
      "Epoch: 41, Training Loss:   0.0502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0618156: : 8it [00:00, 41.33it/s]                          \n",
      "train loss = 0.0471654: : 8it [00:00, 41.58it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Training Loss:   0.0630\n",
      "Epoch: 43, Training Loss:   0.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0527407: : 8it [00:00, 41.61it/s]                          \n",
      "train loss = 0.0322146: : 8it [00:00, 41.66it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Training Loss:   0.0490\n",
      "Epoch: 45, Training Loss:   0.0422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0454268: : 8it [00:00, 41.60it/s]                          \n",
      "train loss = 0.0479545: : 8it [00:00, 41.46it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Training Loss:   0.0532\n",
      "Epoch: 47, Training Loss:   0.0477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0674825: : 8it [00:00, 41.71it/s]                          \n",
      "train loss = 0.0437984: : 8it [00:00, 41.38it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Training Loss:   0.0492\n",
      "Epoch: 49, Training Loss:   0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0440774: : 8it [00:00, 41.11it/s]                          \n",
      "train loss = 0.0388653: : 8it [00:00, 41.15it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Training Loss:   0.0430\n",
      "Epoch: 51, Training Loss:   0.0452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0438150: : 8it [00:00, 41.45it/s]                          \n",
      "train loss = 0.0421106: : 8it [00:00, 41.33it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52, Training Loss:   0.0436\n",
      "Epoch: 53, Training Loss:   0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0398490: : 8it [00:00, 40.52it/s]                          \n",
      "train loss = 0.0416566: : 8it [00:00, 40.37it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54, Training Loss:   0.0424\n",
      "Epoch: 55, Training Loss:   0.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0384727: : 8it [00:00, 41.05it/s]                          \n",
      "train loss = 0.0397632: : 8it [00:00, 41.47it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, Training Loss:   0.0391\n",
      "Epoch: 57, Training Loss:   0.0456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0320677: : 8it [00:00, 41.27it/s]                          \n",
      "train loss = 0.0584648: : 8it [00:00, 41.38it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58, Training Loss:   0.0519\n",
      "Epoch: 59, Training Loss:   0.0469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0378192: : 8it [00:00, 41.42it/s]                          \n",
      "train loss = 0.0593858: : 8it [00:00, 41.65it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Training Loss:   0.0454\n",
      "Epoch: 61, Training Loss:   0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0353049: : 8it [00:00, 40.88it/s]                          \n",
      "train loss = 0.0431182: : 8it [00:00, 41.39it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62, Training Loss:   0.0434\n",
      "Epoch: 63, Training Loss:   0.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0311720: : 8it [00:00, 41.45it/s]                          \n",
      "train loss = 0.0407211: : 8it [00:00, 41.38it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64, Training Loss:   0.0428\n",
      "Epoch: 65, Training Loss:   0.0397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0394151: : 8it [00:00, 41.51it/s]                          \n",
      "train loss = 0.0399318: : 8it [00:00, 41.77it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, Training Loss:   0.0389\n",
      "Epoch: 67, Training Loss:   0.0391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0388029: : 8it [00:00, 41.64it/s]                          \n",
      "train loss = 0.0342117: : 8it [00:00, 41.73it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68, Training Loss:   0.0383\n",
      "Epoch: 69, Training Loss:   0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0340391: : 8it [00:00, 41.68it/s]                          \n",
      "train loss = 0.0339783: : 8it [00:00, 41.57it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70, Training Loss:   0.0382\n",
      "Epoch: 71, Training Loss:   0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0256198: : 8it [00:00, 41.78it/s]                          \n",
      "train loss = 0.0524138: : 8it [00:00, 41.73it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72, Training Loss:   0.0330\n",
      "Epoch: 73, Training Loss:   0.0435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0620144: : 8it [00:00, 41.32it/s]                          \n",
      "train loss = 0.0454649: : 8it [00:00, 41.59it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74, Training Loss:   0.0472\n",
      "Epoch: 75, Training Loss:   0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0426592: : 8it [00:00, 41.11it/s]                          \n",
      "train loss = 0.0468569: : 8it [00:00, 41.25it/s]                          \n",
      "  0%|          | 0/7.8125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76, Training Loss:   0.0397\n",
      "Epoch: 77, Training Loss:   0.0386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss = 0.0312675: : 8it [00:00, 40.06it/s]                          \n",
      "train loss = 0.0414496: : 8it [00:00, 40.57it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78, Training Loss:   0.0395\n",
      "Epoch: 79, Training Loss:   0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "n_epochs = 80\n",
    "stale_epochs = 0\n",
    "loss = 999999\n",
    "train_losses = []\n",
    "for epoch in range(0, n_epochs):\n",
    "    #loss = train(model, optimizer, loader, len(datas), 128, loss_ftn_obj)\n",
    "    loss = train.train(model, optimizer, dataloaders['train'], len(dataloaders['train'].dataset), dataloaders['train'].batch_size, loss_ftn_obj)\n",
    "    train_losses.append(loss)\n",
    "    print('Epoch: {:02d}, Training Loss:   {:.4f}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils_torch.scaler)\n",
    "reload(prepr)\n",
    "reload(plot)\n",
    "\n",
    "inverse_standardization = True\n",
    "plot.plot_reco_for_loader(model, dataloaders['train'], device, scaler_new, inverse_standardization, 'test_train', osp.join(save_dir, 'reconstruction_post_train', 'train_reco_std_log_minmax_inverse_norm'), 'all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_new = utils_torch.scaler.Standardizer(minmax_idx=[3,4],  log_idx=[3,4])\n",
    "scaler_new.std=scaler.std\n",
    "scaler_new.mean=scaler.mean\n",
    "scaler_new.max=scaler.max\n",
    "scaler_new.min=scaler.min\n",
    "scaler_new.minmax_idx = scaler.minmax_idx\n",
    "scaler_new.std_idx = scaler.std_idx\n",
    "scaler_new.log_idx = scaler.log_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.5055, 6.5087])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_new.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1985, 0.1097])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_new.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
